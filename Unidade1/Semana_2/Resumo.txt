Eficiência é otimização do tempo, redução de recursos e uso de baixa potência
Quais são os tipos de complexidade computacional?
-> Tempo: número de passos executados
-> Espaço: tamanho da alocação em memória

void exemplo(uint32_t n) {
c1(); executa 1 vez
for(uint32_t i = 0; i < n; i++) chama n vezes
c2(); executa n vez
for(uint32_t j = 0; j < n; j++) chama n vezes
c3(); executa n vez
 for(uint32_t k = 0; k < n; k++) chama n vezes
c4(); executa n vez
} //por isso o tempo fica de c1 + c2*n + c3*n^2 + c4*n^3
nesse pseudo código, os cx() representam sub-rotinas, isto é, operações elementares ou constantes, 
usadas para análise de complexidade, placeholders que:
-> Executam em tempo fixo (independente do tamanho do input)
-> Podem ser qualquer coisa simples: somar dois números, acessar um vetor, fazer uma comparação, trocar valores, etc

g(n) representa uma função de crescimento que descreve o comportamento do tempo de execução (ou uso de memória)
naquele caso de exemplo(), g(n) = c*n^3, sempre pegando o maior expoente
A análise assintótica é a verificação do tempo de execução baseado no número de passos
O(g(n))	Limite superior: o algoritmo não passa de g(n) exemplo(n) < g(n)
Ω(g(n))	Limite inferior: o algoritmo faz no mínimo g(n) exemplo(n) > g(n)
Θ(g(n))	Limite preciso: o algoritmo faz exatamente g(n)  exemplo(n) = g(n)

Para algoritmos iterativos, ou seja, sem recursão, a análise assintótica ocorre:
identificar operações primitivas;
identificar a quantidade de vezes que cada uma dessas primitivas é executada;
Somar essas execuções.
Você lembra quais são as operações primitivas? 
    - Avaliação de expressões booleanas;
    - Operações matemáticas;
    - Retorno de métodos;
    - Atribuição;
    - Acesso à variáveis e posições arbitrárias de um array

No algoritmo iterativo, quando ele não depende da entrada, sempre será Θ(…),
Caso dependa da entrada, como num algoritmo de ordenação(como a lista estava inicialmente) varia entre O, Θ, Ω


Método Mestre:
Verifique o grau (expoente) de 𝑓(𝑛)
f(n) e compare com log(de a)(na base b)
🔸 Se o grau de 𝑓(𝑛) for menor, é Caso 1 (recursão domina).
T(n) = Θ(n^log(de a)(na base b))
🔸 Se for igual, é Caso 2 (empate).
T(n) = Θ(n^log(de a)(na base b) * log n), se tiver algum log na T(n), simplesmente eleve o log n de Θ à quantidade de
logs em T(n) + 1
🔸 Se for maior, é Caso 3 (trabalho externo domina, verifica regularidade).
 T(n) = Θ(f(n))